{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN demoed with OpenAI Gym\n",
    "\n",
    "+ DQN Configuration: \n",
    "    + Experience Replay + Target Network\n",
    "    + Architecture: CNN + FC\n",
    " \n",
    " \n",
    "+ Gym Environment: `Acrobot-v1`\n",
    "    + Raw pixel input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random \n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create environment\n",
    "env = gym.make('Acrobot-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Experience Replay Memory\n",
    "\n",
    "+ `Transition` - a named tuple representing a single transition in our environment. It maps essentially maps (state, action) pairs to their (next_state, reward) result, with the state being the screen difference image as described later on.\n",
    "+ `ReplayMemory` - a cyclic buffer of bounded size that holds the transitions observed recently. It also implements a `.sample()` method for selecting a random batch of transitions for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "- Takes in 3 consecutive frames stacked together (#input channels = 4), and outputs a vector of size 3, representing $Q(s, Right)$, $Q(s, NoAction)$ and $Q(s, Left)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, h, w):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so comput it.\n",
    "        def conv2d_output_size(size, kernel_size=3, stride=1):\n",
    "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "        \n",
    "        # Takes 3 consecutive images - #channel = 9\n",
    "        self.conv1 = nn.Conv2d(9, 32, kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        # Size Immediately after convolution\n",
    "        conv1w = conv2d_output_size(w, kernel_size=3, stride=1)\n",
    "        conv1h = conv2d_output_size(h, kernel_size=3, stride=1)\n",
    "        # Size after max pooling\n",
    "        conv1w = conv2d_output_size(conv1w, kernel_size=2, stride=2)\n",
    "        conv1h = conv2d_output_size(conv1h, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        # Similarly\n",
    "        conv2w = conv2d_output_size(conv1w, kernel_size=5, stride=2)\n",
    "        conv2h = conv2d_output_size(conv1h, kernel_size=5, stride=2)\n",
    "        conv2w = conv2d_output_size(conv2w, kernel_size=2, stride=2)\n",
    "        conv2h = conv2d_output_size(conv2h, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        conv3w = conv2d_output_size(conv2w, kernel_size=5, stride=2)\n",
    "        conv3h = conv2d_output_size(conv2h, kernel_size=5, stride=2)\n",
    "        conv3w = conv2d_output_size(conv3w, kernel_size=2, stride=2)\n",
    "        conv3h = conv2d_output_size(conv3h, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.elu = nn.ELU()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "        linear_input_size = conv3w * conv3h * 32\n",
    "        self.FC1 = nn.Linear(linear_input_size, 32)\n",
    "        self.FC2 = nn.Linear(32, 16)\n",
    "        self.FC3 = nn.Linear(16, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(self.bn1(self.elu(self.conv1(x))))\n",
    "        x = self.maxpool(self.bn2(self.elu(self.conv2(x))))\n",
    "        x = self.maxpool(self.bn3(self.elu(self.conv3(x))))\n",
    "        x = torch.flatten(x, start_dim=1) # Flatten\n",
    "        x = self.elu(self.FC1(x))\n",
    "        x = self.elu(self.FC2(x))\n",
    "        x = self.elu(self.FC3(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(), T.Resize(100), T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_screen(env):\n",
    "    screen = env.render(mode='rgb_array')\n",
    "    # Transpose to size *C * H * W)\n",
    "    screen.transpose((2, 0, 1))\n",
    "    # Resize to add a batch dimension (B * C * H * W) and send to device\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEICAYAAAB/KknhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4ptlyIlvliEnvlmGnPhmGfp/N1+Wv72StpQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow((get_screen(env).cpu().squeeze(0).numpy() * 255).astype(dtype=np.uint8).transpose(1, 2, 0))\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "gamma = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "target_update = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_screen = get_screen(env)\n",
    "_, _, screen_height, screen_width = init_screen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (conv1): Conv2d(9, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (elu): ELU(alpha=1.0)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (FC1): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (FC2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (FC3): Linear(in_features=16, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net = DQN(screen_height, screen_width).to(device)\n",
    "target_net = DQN(screen_height, screen_width).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, net):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY) # Annealing\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest value for column of each row. \n",
    "            # second column on max result is index of where max element was found, \n",
    "            # so we pick action with the larger expected reward\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(2)]], device=device, dtype=torch.long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action_for_evaluation(state, net):\n",
    "    with torch.no_grad():\n",
    "        return policy_net(state).max(1)[1].view(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_durations(rewards_log):\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    rewards_t = torch.tensor(rewards_log, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(rewards_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(rewards_t) > 100:\n",
    "        means = rewards_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(batch_size, memory, policy_net, target_net):\n",
    "    if len(memory) < batch_size:\n",
    "        return\n",
    "    transitions = memory.sample(batch_size)\n",
    "    # Transpose the batch. This converts batch-array of Transitions to Transition of batch-arrays\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    # Compute a mask of non-final states and concatenate the batch elements \n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s : s is not None, batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    \n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    \n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the columns of actions taken.\n",
    "    # These are the actions which would've been taken for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    \n",
    "    # Compute V(s_{t+1}) for all next states\n",
    "    # Expected values of actions for non_final_next_states are computed based on the \"older\" target_net;\n",
    "    # selecting their best reward with max(1)[0]. \n",
    "    # This is merged based on the mask, such that we'll have either the expected state value or 0 \n",
    "    # in case the state was final\n",
    "    next_state_values = torch.zeros(batch_size, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    \n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * gamma) + reward_batch\n",
    "    \n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 10000\n",
    "ckpt_dir = \"AcrobotV1_pixel_checkpoints/\"\n",
    "save_ckpt_interval = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_log = []\n",
    "i_episode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(file_dir, policy_net, target_net, optimizer, i_episode, episode_durations):\n",
    "    save_dict = {\"policy_net\": policy_net.state_dict(),\n",
    "                 \"target_net\": target_net.state_dict(),\n",
    "                 \"optimizer\": optimizer.state_dict(),\n",
    "                 \"i_episode\": i_episode,\n",
    "                 \"episode_durations\": episode_durations}\n",
    "    # Create the directory if not exist\n",
    "    if not os.path.isdir(file_dir):\n",
    "        os.makedirs(file_dir)\n",
    "    torch.save(save_dict, os.path.join(file_dir, \"ckpt_eps%d.pt\" % i_episode))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(file_dir, i_episode):\n",
    "    checkpoint = torch.load(os.path.join(file_dir, \"ckpt_eps%d.pt\" % i_episode))\n",
    "    \n",
    "    policy_net = DQN(screen_height, screen_width).to(device)\n",
    "    policy_net.load_state_dict(checkpoint[\"policy_net\"])\n",
    "    policy_net.train()\n",
    "    \n",
    "    target_net = DQN(screen_height, screen_width).to(device)\n",
    "    target_net.load_state_dict(checkpoint[\"target_net\"])\n",
    "    target_net.eval()\n",
    "    \n",
    "    optimizer = optim.Adam(policy_net.parameters())\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    \n",
    "    i_episode = checkpoint[\"i_episode\"]\n",
    "    episode_durations = checkpoint[\"episode_durations\"]\n",
    "    \n",
    "    return policy_net, target_net, optimizer, i_episode, episode_durations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmSEiSWpmiEiSmhkikqRmhogkqdn/B1XIJR+WrBPOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4 Cumulative Rewards: -500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b4a8bb4d39f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Select and perform an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy_net.train()\n",
    "\n",
    "while True:\n",
    "    # Every save_ckpt_interval, Check if there is any checkpoint. \n",
    "    # If there is, load checkpoint and continue training\n",
    "    # Need to specify the i_episode of the checkpoint intended to load\n",
    "    if i_episode % save_ckpt_interval == 0 and os.path.isfile(os.path.join(ckpt_dir, \"ckpt_eps%d.pt\" % i_episode)):\n",
    "        policy_net, target_net, optimizer, i_episode, episode_durations = load_checkpoint(ckpt_dir, i_episode)\n",
    "    \n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    screen_0 = get_screen(env)\n",
    "    screen_1 = get_screen(env)\n",
    "    screen_2 = get_screen(env)\n",
    "    state = torch.cat([screen_0, screen_1, screen_2], dim=1)\n",
    "    \n",
    "    episode_reward = 0\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state, policy_net)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        episode_reward += reward\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        # Observe new state\n",
    "        screen_0 = screen_1\n",
    "        screen_1 = screen_2\n",
    "        screen_2 = get_screen(env)\n",
    "        \n",
    "        if not done:\n",
    "            next_state = torch.cat([screen_0, screen_1, screen_2], dim=1)\n",
    "        else:\n",
    "            next_state = None\n",
    "            \n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        \n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        \n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model(batch_size, memory, policy_net, target_net)\n",
    "        if done:\n",
    "            # Save and print episode stats\n",
    "            rewards_log.append(episode_reward)\n",
    "            plot_durations(rewards_log)\n",
    "            print(\"Episode: %d Cumulative Rewards: %d\" % (i_episode + 1, episode_reward))\n",
    "            break\n",
    "            \n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % target_update == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "    # Every save_ckpt_interval, save a checkpoint according to current i_episode.\n",
    "    # Note that we use i_episode + 1\n",
    "    if (i_episode + 1) % save_ckpt_interval == 0:\n",
    "        save_checkpoint(ckpt_dir, policy_net, target_net, optimizer, i_episode + 1, episode_durations)\n",
    "    \n",
    "    \n",
    "    i_episode += 1\n",
    "        \n",
    "print(\"Complete\")\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation / Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "policy_net.eval()\n",
    "screen_0 = get_screen(env)\n",
    "screen_1 = get_screen(env)\n",
    "screen_2 = get_screen(env)\n",
    "state = torch.cat([screen_0, screen_1, screen_2], dim=1)\n",
    "\n",
    "for t in count():\n",
    "    # Select and perform an action\n",
    "    action = select_action(state, policy_net)\n",
    "    _, reward, done, _ = env.step(action.item())\n",
    "    reward = torch.tensor([reward], device=device)\n",
    "\n",
    "    # Observe new state\n",
    "    screen_0 = screen_1\n",
    "    screen_1 = screen_2\n",
    "    screen_2 = get_screen(env)\n",
    "\n",
    "    if not done:\n",
    "        next_state = torch.cat([screen_0, screen_1, screen_2], dim=1)\n",
    "    else:\n",
    "        next_state = None\n",
    "\n",
    "    # Store the transition in memory\n",
    "    memory.push(state, action, next_state, reward)\n",
    "\n",
    "    # Move to the next state\n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        print(\"Cumulative Rewards: %d\" % (t + 1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1be49fa58>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARQAAAD8CAYAAAC2EFsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3fw/D8xf6+ayWjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "test_screen = env.render(mode=\"rgb_array\")\n",
    "plt.imshow(test_screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1be4f54e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_screen_resized = get_screen(env)\n",
    "plt.imshow((test_screen_resized.cpu().squeeze(0).numpy().transpose(1, 2, 0) * 255).astype(dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.memory[-1].reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
